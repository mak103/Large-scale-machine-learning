{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from geopy.distance import vincenty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../Utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../Data/Train/Train_dataset.csv')\n",
    "data_train.drop('Unnamed: 0',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_validation = pd.read_csv('../Data/Test/test_dataset.csv')\n",
    "data_validation.drop('Unnamed: 0',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = pd.read_csv('bs.csv') #bs contains the latitude and longitude of each base station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_bsid = list(np.sort(data_train['bsid'].unique())) #corresponds to the index of bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data_train[['latitude','longitude']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get index of base station for every item in the data_train\n",
    "bs_index = []\n",
    "bsid = data_train['bsid'].values\n",
    "for i in range(len(data_train)):\n",
    "    bs_index.append(list_bsid.index(bsid[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def calculate_each_distance(y,bs_index, base):\n",
    "    distance = np.zeros(len(y))\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        latA = (y[i][0] * math.pi/180.0)\n",
    "        lngA = (y[i][1] * math.pi/180.0)\n",
    "        index = bs_index[i]\n",
    "        latB = (base[index][0] * math.pi/180.0)\n",
    "        lngB = (base[index][1] * math.pi/180.0)\n",
    "        a = latA - latB\n",
    "        b = lngA - lngB\n",
    "        s = 2*6371*math.asin(math.sqrt(math.pow(math.sin(a/2),2)\n",
    "                                       +math.cos(latA)*math.cos(latB)*math.pow(math.sin(b/2),2)))\n",
    "        distance[i] = s\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#distance between device and the base station\n",
    "distance = calculate_each_distance(y,bs_index, bs.values)\n",
    "data_train['distance'] = pd.DataFrame(distance,columns=['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def calculate_each_angle(y,bs_index, base):\n",
    "    angle = np.zeros(len(y))\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        index = bs_index[i]\n",
    "        x1 = base[index][0]\n",
    "        y1 = base[index][1]\n",
    "        x2 = y[i][0]\n",
    "        y2 = y[i][1]\n",
    "        xx = x2 - x1\n",
    "        yy = y2 - y1\n",
    "        if xx == 0:\n",
    "            angle_temp = math.pi / 2.0\n",
    "        else:\n",
    "            angle_temp = math.atan(math.fabs(yy/xx))\n",
    "            \n",
    "        if xx < 0 and yy >= 0:\n",
    "            angle_temp = math.pi - angle_temp\n",
    "        elif xx < 0 and yy < 0:\n",
    "            angle_temp = math.pi + angle_temp\n",
    "        elif xx >= 0 and yy < 0:\n",
    "            angle_temp = math.pi * 2.0 - angle_temp\n",
    "            \n",
    "        angle[i] = angle_temp\n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# angles between device and the base station\n",
    "angle = calculate_each_angle(y,bs_index, bs.values)\n",
    "data_train['angle'] = pd.DataFrame(angle,columns=['angle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train['rssi2'] = 10 ** ((np.abs(data_train['rssi'])-47)/38.75)\n",
    "data_validation['rssi2'] = 10 ** ((np.abs(data_validation['rssi'])-47)/38.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some items of 'data_type' are wirtten as 'Wifi' instead of 'wifi'\n",
    "data_train['data_type'] = data_train['data_type'].str.lower()\n",
    "data_validation['data_type'] = data_validation['data_type'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type_train = pd.get_dummies(data_train['data_type'], drop_first=True)\n",
    "data_type_validation = pd.get_dummies(data_validation['data_type'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', dtype='uint8').fit(data_train['dtid'].values.reshape(-1, 1))\n",
    "dtid_train = pd.DataFrame(ohe.transform(data_train['dtid'].values.reshape(-1, 1)).A)\n",
    "dtid_validation = pd.DataFrame(ohe.transform(data_validation['dtid'].values.reshape(-1, 1)).A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([data_train['rssi'],data_train['rssi2'],data_train['snr'],data_type_train, dtid_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.concat([data_validation['rssi'],data_validation['rssi2'],data_validation['rssi'],data_type_validation, dtid_validation],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = data_train['distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried linear regression, random forest and the xgboost. The random forest(n_estimators = 100, max_depth=10) and the xgboost(with the parameters: n_estimators = 100, learning_rate = 0.08) would take nearly one hour to fit the train and test. On the contrary, the linear regression can fit quickly can has even a better performance on the the predict result. So finally I chose to apply linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(reg.predict(X_test),columns=['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = data_validation.groupby('messageid').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a 159-columns matrix, each row is a unique message_id, each column means the distance to this station.\n",
    "dict_index={}\n",
    "message_id = []\n",
    "array_distance = scipy.sparse.lil_matrix((len(g), len(list_bsid)))\n",
    "j = 0\n",
    "for gg in g:\n",
    "    temp = []\n",
    "    message_id.append(data_validation['messageid'][g[gg][0]])\n",
    "    for i in range(len(g[gg])):\n",
    "        message_index = g[gg][i]\n",
    "        temp.append(g[gg][i])\n",
    "        bsid_index = list_bsid.index(data_validation['bsid'][message_index])\n",
    "        message_distance = y_test['distance'][message_index]\n",
    "        array_distance[j, bsid_index] = message_distance\n",
    "    dict_index[j] = temp\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "message_id = pd.DataFrame(message_id, columns=['messageid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(array_distance.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@njit\n",
    "def calculate_lat_lng(X, bs):\n",
    "    y = np.zeros((len(X),2))\n",
    "    for i in range(len(X)):\n",
    "        num_point = 0\n",
    "        point_distance = []\n",
    "        point_index = []\n",
    "        for j in range(159):\n",
    "            if X[i,j] != 0:\n",
    "                point_distance.append(X[i,j])\n",
    "                point_index.append(j)\n",
    "                num_point += 1\n",
    "        if num_point == 1:\n",
    "            index = int(point_index[0])\n",
    "            y[i][0] = bs[index,0]\n",
    "            y[i][1] = bs[index,1]\n",
    "        if num_point == 2:\n",
    "            index1 = int(point_index[0])\n",
    "            index2 = int(point_index[1])\n",
    "            y[i][0] = ((bs[index1,0]*point_distance[1])+(bs[index2,0]*point_distance[0]))/(point_distance[1]+point_distance[0])\n",
    "            y[i][1] = ((bs[index1,1]*point_distance[1])+(bs[index2,1]*point_distance[0]))/(point_distance[1]+point_distance[0])\n",
    "        if num_point > 2:\n",
    "            point_distance = np.array(point_distance)**2\n",
    "            sum_distance = sum(point_distance)\n",
    "            for k in range(num_point):\n",
    "                index = int(point_index[k])\n",
    "                y[i][0] = y[i][0] + (bs[index,0]*point_distance[k])/sum_distance\n",
    "                y[i][1] = y[i][1] + (bs[index,1]*point_distance[k])/sum_distance\n",
    "    return y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the message which is only received by one base station, I don’t have method but can only set the location of this base station as the location. As for the message which is received by 2 base stations, I find a coordinate between those two base stations by use the proportion of the predicted distance to those two stations. As for the message which is received by more than 2 base stations, I’m not sure how to deal it, and I just used a rough way to calculate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = calculate_lat_lng(X.values, bs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_y = pd.DataFrame(y, columns=['latitude','longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_y_test = pd.concat([message_id,df_y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_y_test.to_csv('WANG_Yuqing.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
